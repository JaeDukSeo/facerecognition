<html>
  <head>
    <!--  Face API and CSV API    -->
    <script src="face-api.min.js"></script>
    <style>
          :root {
        --color-bg: #f9f3f9;
        --color-camera-lightest: #858193;
        --color-camera-lighter: #726f80;
        --color-camera-light: #403c49;
        --color-camera-dark: #34323e;
      }

      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }
      body {
        background: var(--color-bg);
        display: flex;
        justify-content: center;
        min-height: 100vh;
        align-items: center;
        flex-direction: column;
      }

      /* for the camera, cap the size of the container, but maintain a 1: 3/5 ratio between width and height */
      main.camera {
      	margin: 3rem 0 2rem;
        width: 90vw;
        height: calc(90vw * 3 / 5);
        max-width: 550px;
        max-height: calc(550px * 3 / 5);
        /* slight gradient toward the top of the camera */
        background: linear-gradient(
          to top,
          var(--color-camera-dark) 55%,
          var(--color-camera-light)
        );
        border-radius: 30px;
        /* filter to consider a shadow also on the connected pseudo element */
        filter: drop-shadow(0 1px 2px var(--color-camera-light));
        position: relative;
        /* padding to reduce the size of the nested canvas */
        padding: 2rem;
        /* flex to center the canvas in the camera */
        display: flex;
        justify-content: center;
        align-items: center;
      }
      /* with a pseudo element add a small appendage at the top of the camera */
      main.camera:before {
        position: absolute;
        content: "";
        background: var(--color-camera-light);
        bottom: 100%;
        left: 50%;
        width: 60%;
        height: 2.5rem;
        transform: translateX(-50%);
        border-radius: 20px;
        border-bottom-left-radius: 0;
        border-bottom-right-radius: 0;
      }

      /* for the canvas, include it as a circle with a solid background
      the idea is to give the feed from the webcam in this element
      */
      canvas.camera__feed {
        height: 100%;
        width: calc(100% * 3 / 5);
        background: var(--color-camera-dark);
        border-radius: 50%;
        border: 1rem solid var(--color-camera-lightest);
      }

      /* button to trigger the picture being taken
      absolute positioned in the top right corner */
      button.camera__click {
        background: var(--color-camera-lightest);
        width: 28px;
        height: 28px;
        border: none;
        border-radius: 50%;
        position: absolute;
        top: 2rem;
        right: 3rem;
        transition: all 0.2s ease-out;
      }
      /* pseudo element depicting a slightly darker border around the button */
      button.camera__click:before {
        position: absolute;
        content: "";
        background: var(--color-camera-dark);
        top: 50%;
        left: 50%;
        width: 100%;
        height: 100%;
        transform: translate(-50%, -50%) scale(1.5);
        border-radius: 50%;
        z-index: -5;
      }
      /* on hover change the color to the slightly darker hue */
      button.camera__click:hover {
        background: var(--color-camera-lighter);
      }

      /* for the container of the photos, display them in a row */
      div.photos {
        display: flex;
        align-items: center;
        /* cap the width like the main container */
        width: 90vw;
        max-width: 600px;
        height: 150px;
        margin-top: 1rem;
        overflow-x: auto;
        overflow-y: hidden;
      }

      /* give a fixed width and height to the anchor link nesting the images */
      div.photos img {
        height: 100px;
        width: 100px;
        flex-shrink: 0;
        margin: 1rem;
        animation: introduce 0.25s cubic-bezier(0.05, 1.18, 0.75, 1.31) both;
        /* position relative for a connected pseudo element */
        position: relative;
      }

      /* minor stylistic choices regarding the scrollbar */
      div.photos::-webkit-scrollbar {
        height: 0.35rem;
      }
      div.photos::-webkit-scrollbar-track {
        box-shadow: inset 0 0 6px var(--color-camera-dark);
      }
      div.photos::-webkit-scrollbar-thumb {
        background: var(--color-camera-light);
        border-radius: 5px;
      }

      /* simple animation to make each new picture bounce into view */
      @keyframes introduce {
        from {
          opacity: 0;
          visibility: hidden;
          transform: scale(0) rotate(12deg);
        }
        to {
          opacity: 1;
          visibility: visible;
          transform: scale(1) rotate(0);
        }
      }
    </style>
  </head>

  <body>
    <h3 align="center">
      Please Click Run
      <br />
      <a href="facemesh.html">Face Mesh Demo</a>
    </h3>

    <a href="iteration/2020_07_15_Top_Three.html"
      >iteration/2020_07_15_Top_Three.html</a
    >
    <a href="iteration/2020_07_14_robust.html"
      >iteration/2020_07_14_robust.html</a
    >
    <a href="iteration/2020_07_13_basic_looklike _finder.html"
      >iteration/2020_07_13_basic_looklike _finder.html</a
    >
    <a href="iteration/2020_07_11_basic_version.html"
      >iteration/2020_07_11_basic_version.html</a
    >
    <a href="iteration/2020_07_11_age_gender_emotion_landmarks.html"
      >iteration/2020_07_11_age_gender_emotion_landmarks.html</a
    >
    <br />
    <div id="myDiv01">
      <h1>
        To Take a Photo please click on the button located on the right corner
        of the camera
      </h1>
    </div>
    <br />
    <h1 id="mainheader">
      You Look Like
    </h1>
    <br />

    <br /><br />

    <main class="camera">
      <button class="camera__click"></button>
      <canvas class="camera__feed"></canvas>
    </main>

    <div class="photos"></div>

    <div>
      <img
        width="30%"
        height="auto"
        id="imageid1"
        src="https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F1.jpg?v=1594348794335"
        style=" border: 1px solid #ddd;display: inline;"
      />
      <img
        width="30%"
        height="auto"
        id="imageid2"
        src="https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F1.jpg?v=1594348794335"
        style=" border: 1px solid #ddd;display: inline;"
      />
      <img
        width="30%"
        height="auto"
        id="imageid3"
        src="https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F1.jpg?v=1594348794335"
        style=" border: 1px solid #ddd;display: inline;"
      />
    </div>
    <br />

    <script>
      // This is for the Camera UI
      const camera = document.querySelector("main.camera");
      const canvas = camera.querySelector("canvas.camera__feed");
      const { width, height } = canvas;
      const context = canvas.getContext("2d");
      const click = camera.querySelector("button.camera__click");
      const photos = document.querySelector("div.photos");
      const displaySize = { width: canvas.width, height: canvas.height };
      faceapi.matchDimensions(canvas, displaySize);

      // Main variable needed to run the detection
      const temp_image_url = {
        1: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F1.jpg?v=1594348794335",
        2: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F2.jpg?v=1594348798736",
        3: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F3.jpg?v=1594348802983",
        4: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F4.jpg?v=1594348795521",
        5: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F5.jpg?v=1594348803506",
        6: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F6.jpg?v=1594348804077",
        7: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F7.jpg?v=1594348805187",
        8: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F8.jpg?v=1594348805783",
        9: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F9.jpg?v=1594348807264",
        10: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F10.jpg?v=1594348807524",
        11: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F11.jpg?v=1594348796291",
        12: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F12.jpg?v=1594348807073",
        13: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F13.jpg?v=1594348799403",
        14: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F14.jpg?v=1594348799981",
        15: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F15.jpg?v=1594348796224",
        16: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F16.jpg?v=1594348795284",
        17: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F17.jpg?v=1594348796716",
        18: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F18.jpg?v=1594348800076",
        19: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F19.jpg?v=1594348797417",
        20: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F20.jpg?v=1594348795846",
        21: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F21.jpg?v=1594348802314",
        22: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F22.jpg?v=1594348797712",
        23: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F23.jpg?v=1594348802427",
        24: "https://cdn.glitch.com/4f2917f5-212e-426b-9f8b-db9886bfbc92%2F24.jpg?v=1594348804904"
      };
      const labels = [];
      const maxDescriptorDistance = 0.9;
      var faceMatcher;
      for (var key in temp_image_url) labels.push(key);

      load_weights().then(() => {
        const labeledFaceDescriptors = Promise.all(
          labels.map(async label => {
            console.log(" [INFO] Capturing : ", label);
            // fetch image data from urls and convert blob to HTMLImage element
            const img = await faceapi.fetchImage(temp_image_url[label]);

            // detect the face with the highest score in the image and compute it's landmarks and face descriptor
            const fullFaceDescription = await faceapi
              .detectSingleFace(img)
              .withFaceLandmarks()
              .withFaceDescriptor();

            if (!fullFaceDescription) throw new Error("no faces detected!");
            const faceDescriptors = [fullFaceDescription.descriptor];
            return new faceapi.LabeledFaceDescriptors(label, faceDescriptors);
          })
        ).then(function(data) {
          console.log(" [INFO] Loaded all of the face models ");
          alert("READY! Please give the camera permission!");
          faceMatcher = new faceapi.FaceMatcher(data, maxDescriptorDistance);
          getVideo();
        });
      });

      // Click Button
      async function handleClick() {
        var top_three = {};
        const data = canvas.toDataURL("image/jped");
        const img = document.createElement("img");

        //         Create the img and put that in
        img.src = data;
        photos.insertBefore(img, photos.firstChild);

        // Compare the obtain face to API
        const img_detect = await faceapi.fetchImage(data);
        const detection = await faceapi
          .detectSingleFace(img_detect, new faceapi.SsdMobilenetv1Options())
          .withFaceLandmarks()
          .withFaceDescriptor();

        // If a face have been detected
        if (detection) {
          // Compute the distance for all features
          faceMatcher.labeledDescriptors.map(({ descriptors, label }) => {
            top_three[label] = faceMatcher.computeMeanDistance(
              detection.descriptor,
              descriptors
            );
          });

          // Create items array and compute the top 3
          var items = Object.keys(top_three).map(function(key) {
            return [key, top_three[key]];
          });
          items.sort(function(first, second) {
            return first[1] - second[1];
          });
          top_three = items.slice(0, 3);

          document.getElementById("mainheader").innerHTML =
            " Top 1 " +
            top_three[0][0] +
            " Distance: " +
            top_three[0][1] +
            "<br/>" +
            " Top 2 " +
            top_three[1][0] +
            " Distance: " +
            top_three[1][1] +
            "<br/>" +
            " Top 3 " +
            top_three[2][0] +
            " Distance: " +
            top_three[2][1] +
            "<br/>";

          document.getElementById("imageid1").src =
            temp_image_url[top_three[0][0]];
          document.getElementById("imageid2").src =
            temp_image_url[top_three[1][0]];
          document.getElementById("imageid3").src =
            temp_image_url[top_three[2][0]];
        }
      }
      click.addEventListener("click", handleClick);

      // Get video for camera
      function getVideo() {
        navigator.mediaDevices
          .getUserMedia({ video: true, audio: false })
          .then(mediaStream => {
            // create a video element
            const video = document.createElement("video");
            video.srcObject = mediaStream;
            video.play();
            videoToCanvas(video);
          });
      }

      // Video to canvas element
      async function videoToCanvas(video) {
        async function temp(video) {
          context.drawImage(video, 0, 0, width, height);
        }

        setInterval(() => {
          temp(video);
        }, 16);
      }

      // Main Function for detection and display
      async function onPlay() {
        // Prepare for the overlaying of detection
        var top_three = {};
        const videoEl = document.getElementById("inputVideo");
        const old_canvas = document.getElementById("overlay");
        const displaySize = { width: canvas.width, height: canvas.height };
        faceapi.matchDimensions(canvas, displaySize);

        // Start detecting
        const detection = await faceapi
          .detectSingleFace(videoEl, new faceapi.SsdMobilenetv1Options())
          .withFaceLandmarks()
          .withFaceDescriptor();

        // If a face have been detected
        if (detection) {
          // Compute the distance for all features
          faceMatcher.labeledDescriptors.map(({ descriptors, label }) => {
            top_three[label] = faceMatcher.computeMeanDistance(
              detection.descriptor,
              descriptors
            );
          });

          // Create items array and compute the top 3
          var items = Object.keys(top_three).map(function(key) {
            return [key, top_three[key]];
          });
          items.sort(function(first, second) {
            return first[1] - second[1];
          });
          top_three = items.slice(0, 3);

          document.getElementById("mainheader").innerHTML =
            " Top 1 " +
            top_three[0][0] +
            " Distance: " +
            top_three[0][1] +
            "<br/>" +
            " Top 2 " +
            top_three[1][0] +
            " Distance: " +
            top_three[1][1] +
            "<br/>" +
            " Top 3 " +
            top_three[2][0] +
            " Distance: " +
            top_three[2][1] +
            "<br/>";

          document.getElementById("imageid1").src =
            temp_image_url[top_three[0][0]];
          document.getElementById("imageid2").src =
            temp_image_url[top_three[1][0]];
          document.getElementById("imageid3").src =
            temp_image_url[top_three[2][0]];

          const resizedDetections = faceapi.resizeResults(
            detection,
            displaySize
          );
          faceapi.draw.drawDetections(canvas, resizedDetections);
          faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
        }
        setTimeout(() => onPlay());
      }

      // Load the weigths and start
      async function load_weights() {
        await faceapi.loadSsdMobilenetv1Model(
          "https://jaedukseo.github.io/face_weights/"
        );
        await faceapi.loadFaceLandmarkModel(
          "https://jaedukseo.github.io/face_weights/"
        );
        await faceapi.loadFaceRecognitionModel(
          "https://jaedukseo.github.io/face_weights/"
        );
      }

      // Load the weigths and start
      async function run() {
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
        const videoEl = document.getElementById("inputVideo");
        videoEl.srcObject = stream;
      }
    </script>
  </body>
</html>
